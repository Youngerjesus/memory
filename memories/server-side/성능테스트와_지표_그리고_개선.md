# Infra 공방 2주차 과정

## 서비스의 성능 확인 방법

- WebPageTest 로 서버에서 브라우저로 가져와서 렌더링을 하는 부분의 테스트
- 부하테스트로 브라우저 렌더링을 제외한 전 구간 (DB - 서버 - 클라이언트) 을 테스트

## 웹 성능 테스트

- 회사는 고객 만족을 주기위해 수익을 낸다.
- 성능은 고객 만족에 영향을 준다. 경쟁사와 성능이 20% 이상의 차이가 날 때 성능의 차이를 느낀다.
- 3  초 안에 로딩이 되지 않으면 53% 의 사용자가 떠난다.

## 성능 테스트를 할 때 우선순위를 고려하자.

- 사용자가 많은 페이지가 무엇인지 가장 중요한 페이지가 무엇인지 고민해보자.
- 경쟁 사이트와 유사 사이트의 성능도 조사를 해보자. 그걸 통해서 우리의 목표점도 정해질 수 있다.
- 사용자에게 컨텐츠가 빠르게 노출되는 것이 중요한지

## WebPageTest

- HTML, CSS, JS, 이미지, 폰트와 같은 정적 리소스를 받는다. 이런 정적 리소스와 네트워크 상태에 영향을 받는 지표가 있고
- 웹 서버에서 영향을 받는 지표가 있다.
    - TLS 및 보안과 관련된 지표
    - 웹 서버에서 받은 첫번째 바이트가 얼마만에 도착을 했는가? (서버 응답시간 + 네트워크 비용)
    - keep-alive 설정을 했는지? (매번 3way handshake 등의 과정을 거치는지, 아니면 Connection 을 재사용하는지?)
    - HTTP gzip 압축을 했는지? (우리의 브라우저는 gzip 압축 프로그램을 내장하고 있다. 압축을 하면 Content-Encoding 에 gzip 이 포함된다.)
    - 이미지 압축을 헀는지? (사용자는 이미지의 품질보다 네트워크 지연에 더욱 민감하다.)
    - 정적 컨텐츠를 캐싱해서 사용하는지? (불필요한 요청 자체를 지우자.)
    - CDN 을 사용하는지? (이왕이면 가까운 곳에서 받는게 더욱 효과적이다.)

## 웹 성능 예산 예)

- 메인 페이지의 모든 오브젝트 파일 크기는 10MB 미만으로 제한한다.
- 검색 페이지에는 2MB 미만의 이미지가 포함되어야 한다.
- 자바스크립트 크기는 1MB 를 넘으면 안된다.
- LTE 환경에서 모바일 기기의 Time to Interactive 는 5초 미만이어야 한다.
- Dom Content Loaded 는 10 초 First Meaningful Paint 는 15 초 미만이어야 한다.
- Lighthouse 성능 감사에서 80 점 이상을 받아야한다.

## 부하테스트

- 장애가 없을 수 없으니까 장애내성을 가진 서비스를 만들어야 한다. 이를 위해서는 현재 시스템이 얼만큼의 부하를 견디는지 알고 있어야 한다. 그리고 병목 지점이 어디인지도 알아야한다. 그리고 이를 통해 장애날 때 어떻게 대응할지 계획할 수 있다.
- 가용성을 높이기 위해서는 단일 장애점 (SPOF) 를 없애야한다. DB 서버도 단일 장애점이 될 수도 있다.
- 성능의 지표는 크게 3 가지로 이뤄진다.
    - 얼마나 많은 사람들이 동시에 사용할 수 있는지 (Users)
        - 유저를 구분할 땐 로그인 한 유저와 로그인 하지 않은 유저가 있고 성능 테스트를 할 땐 실제로 서버를 사용하는 Active User (= VUser) 로 생각하고 한다.
    - 일정 시간동안 얼마나 많은 처리를 할 수 있는지 (TPS)
        - 사용자에게 일정 수준의 응답을 주다가 어느 지점을 넘어가기 시작하면 응답들이 큐에 쌓이면서 급격하게 증가하는 구간이 있다. 이 한계점을 파악하는 것이다.
        - 단일 사용자에 대해서 응답이 느린 경우에 빨라지고 싶다면 Scale up (물론 병목 지점을 해결해서 올릴 수도 있다.)
        - 부하가 많아져서 응답이 느려지는 경우에는 Scale out
    - 서비스가 얼마나 빠른지 (TIme)
        - 사용자에겐 결국 응답 시간만 보인다.

## 부하 테스트 종류 1) Smoke Test

- 최소한의 부하로 테스트의 시나리오 오류를 검증
- 최소 부하 상태에서 시스템 오류가 없는지 검증하는 것.

## 부하테스트 종류 2) load Tset

- 서비스의 평소 트래픽과 최대 트래픽으로 구성한다.
- 기능이 정상 동작하는지 검증
- 그리고 배포, 인프라 변경 (Scale out, DB Failover) 시 성능 변화를 확인

## 부하테스트 종류3) Stress Test

- 점진적으로 부하가 증가하도록 구성한다.
- 최대 사용자, 최대 처리량등을 확인하는지 검증하는 용도로 사용한다.

## 부하 테스트 도구)

- 부하 테스트는 3 가지 요건이 충족되어야 한다.
- 시나리오 기반의 테스트가 가능해야한다.
- 동시 접속자 수, 요청 간격, 최대 처리량 등 부하 조정이 가능해야 한다.
- 부하 테스트 서버 자체도 굉장히 많은 부하를 주니까 Scale out 을 지원해야한다.
- 예시로는 ngrinder, K6 가 있다.

## 성능 목표를 정하자

- DAU (알 수 없다면 가설을 세워야한다.)
- 피크 시간대 집중률 (최대 트래픽 / 평소 트래픽)
- 1 명당 1 일 평균 요청 수
- 1 일 사용자 수 (DAU) X 1 명당 1 일 평균 접속 수 = 1 일 총 접속수
- 1일 총 접속수 / 86,400 (초/일) = 1 일 평균 RPS (Request per seconds)
- 1 일 평균 rps X (최대 트래픽 / 평소 트래픽) = 1 일 최대 rps)
- 예시) DAU 8,640,000, 피크 시간대 집중률 = 10, 1일 요청 수 = 1
    - 1 일 총 접속 수 = 8,640,000
    - 1 일 평균 RPS = 100
    - 1 일 최대 RPS = 1,000
- 이번 미션에서는 각 요청별 latencty 는 50 ~ 100 ms 로 해보자.
- VUser 는 얼마로 정하나?
    - 목표 rps = (VUser * 요청 수) / 목표 응답시간 (T)
    - VUser = (목표 rps * T) / 요청 수
    - 목표 응답시간 T 와 목표 rps 를 정해야 한다. 요청 수는 T 를 정할 때 계산하는 시나리오에 따라서 다르다.
    - T = (요청 수 * http_req_duration) + a 로 정하면 된다. (a 는 다른 외부 시스템을 이용하거나, 모킹을 하는 경우에 예상하는 지연시간을 말한다.)


## 테스트 기간

- 일반적으로 부하 테스트는 30 분에서 2 시간 정도를 권장한다.
- 부하가 주어진 상황에서 여러가지 상황을 부여해보면서 서비스 성능을 확인해보자. DB Failover, Rolling Update 배포 등

## 시나리오를 정해보자.

- 접속 빈도가 높은 기능 위주로
- 서버 리소스 소비량이 높은 기능 위주로
- DB 를 사용하는 기능 위주로
- 외부 시스템과 통신하는 기능 위주로

## 주의할 점

- 성능 테스트는 실제 사용자가 접속하는 환경과 같은 곳에서 해야한다. 내부에서 하면 네트워크 변수로 인해서 응답 시간의 차이가 날 것.
- 부하 테스트는 클라이언트 내부 처리 시간이 배제되어 있음을 알아야 한다.
- 테스트 DB 에 들어있는 데이터의 양이 실제 운영 DB 와 동일해야 한다. 통상 전체 성능의 70% 이상이 DB 에 좌우되는데 테스트 대상이 되는 테이블의 데이터 양이 다르면 쿼리의 실행계획이 달라져서 성능이 다르게 나타날 수 있다.
- 운영환경의 경우 서비스 요청외에 별도로 수행하는 배치나 후속작업으로 인한 부하가 있을 수 있다. 이를 고려해야한다.
- 외부 시스템과의 통신을 이용하는 경우 시스템과 별도의 서버로 분리를 해야한다. 그래야 Http Connection Pool 과 Thread 를 사용하기 때문이다.

## 부하테스트시 서버의 상태는 어떻게 알까?

- 우리의 컴퓨터 시스템은 크게 4 가지 구성요소를 가진다. (CPU, Memory, Disk, Network Card)
- 이런 각 시스템 자원들은 두 가지 상태가 있다. 여유가 있거나, 포화상태이거나.
- 우리가 획득할 수 있는 정보는 3 가지 형태가 있다. 요약정보, 이벤트 기록, 스냅샷.
    - 요약은 단위 시간동안의 평균을 보여준다. (sar, vmstat 등)
    - 이벤트 기록은 패킷과 시스템 콜을 말한다.
    - 스냅샷은 순간의 상태를 기록하는 것을 말한다. (top 명령등)
    - 주로 요약정보로 대략적인 상태를 파악하고 스냅샷으로 원인을 파악한다.
    - 이벤트 기록은 재현을 할 때 주로 사용된다.

## USE 방법론

- 응답이 느려지는 경우에는 이런식으로 처리할 것 같다.
    - 접속 로그로 느린 응답을 보고
    - vmstat 으로 사용률을 보고
    - ps 로 스냅샷을 찍어서 용의자를 본다.
- 문제상황 파악엔 USE 를 쓴다.
    - Utilization: 얼만큼 자원을 썼는지.
    - Saturation: 얼마나 많은 부하가 몰리는지.
    - Error: 에러가 발생했는지
    - 판단하는 기준은 E → U → S 이다.
- 토스의 서버 인프라 모니터링을 보자.
- 에러를 보려면 로그를 남겨야 한다. 로그만 확인해도 원인과 해결방안을 찾을 수 있다.
- 이를 통해서 특정 사용자, 시간, 조건에 따라 발생하는지 맥락을 파악하고 그것들을 재현해나가면서 주로 문제를 해결해나간다.

## 로그란

- 시스템 로그와 애플리케이션 로그가 있다.
- 로깅을 남길 땐 성능의 이슈가 없도록 side-effect 와 같은 걸 피하도록 해야하고, 필요한 정보들을 모두 담아야한다. 그리고 개인 정보와 같은 것들은 마스킹해야한다.
- 로그 레벨은 다음과 같다.
    - ERROR: 예상치 못한 문제가 발생했다는 의미.
    - WARN: 로직상 유효성을 확인하고 예상 가능한 문제로 인한 예외처리등을 남긴다. 운영할 순 있지만 주의해야한다.
    - INFO: 운영에 참고할만한 사항으로 중요한 비즈니스 프로세스를 위해서 필요하다.
    - DEBUG,TRACE: 개발 단계에서만 사용하고 운영 단계에서는 사용하지 않는다.

## 사용률

- 사용률로도 문제상황을 인지할 수 있다.
- 주로 서버의 경우 CPU, Memory, RX/TX 패킷량, Disk 사용률 IOPS 등을 확인한다.
- vmstat 으로 단위시간동안의 요약을 볼 수 있다.

## CPU 사용률

- 지표는 다음과 같다. us,sy,id,wa,st
    - user time
    - system time
    - idle
    - wait i/o: 이 지표를 참고하기 보다는 process 의 block 상태를 확인하는 경우가 많다.
    - stolen time: hyperviser 가 차지한 시간
- CPU 사용률이 높다라는 건 잘쓰고 있다는 뜻이다. 하지만 100 % 라면 포화상태를 말하는 거고 이 이상은 처리할 수 없다는 의미다. 즉 요청이 대기할 수 있다는 뜻.

## Memory 사용률

- si, so (swap in, swap out) 이 발생하는지 체크한다.
- 스왑이 발생한다면 RSE 가 큰 프로세스를 확인해보자.
- RSE: 실제 물리 메모리 영역의 크기
- VIRT: 프로세스가 확보한 가상 메모리 영역의 크기

## Network 사용률

- active/s 서버에서 다른 외부 장비로 연결한 횟수
- passive/s 서버에 새로 접근한 클라이언트 수

## 부하 상태를 보는 것

- load 를 통해서 볼 수 있다. 상태가 R 과 D 인 프로세스 개수의 평균 값을 말한다.
- R 과 D 상태는 I/O 작업을 대기하는 상태인 프로세스와 실행을 기다리고 있는 프로세스의 상태를 말한다.
- 부하의 정의는 처리할려고 해도 실행할 수 없어서 대기하고 있는 프로세스의 개수를 말한다.
- 부하의 체크는 다음과 같다.
    - Load average 가 core 의 수보다 높은지 아는지
    - Memory swap 이 발생하는지
    - Network 재전송 비율 (retrans/s) 가 0.5% 보다 높은지


## time_wait, close_wait 상태는 장애일까?

- netstat 으로 조회를 했을 때 Connection 의 상태가 이 경우일 때
- 부하가 걸려있다면 estabilish 상태이다.
- time_wait 은 정상적인 상태나 너무 많으면 장애로 이어질 수 있는 상태이고
- close_wait 는 장애 상황에서만 볼 수 있는 상태다.
- time_wait 은 클라이언트에서만 나타나는 TCP 종료과정중에 나타나는 상태고 close_wait 는 서버에서 볼 수 있는 상태다.
- time_wait 상태에서 마지막 ack 를 보내는데 이걸 서버가 받고 closed 상태가 된다. time_wait 상태가 없다면 마지막 ack 가 유실되는 경우에는 서버는 종료하지 못하는 상태가 된다. 그리고 이후의 클라이언트의 요청은 실패한다.
- 다만 time_wait 상태도 결국 소켓을 사용하고 있는 상태이므로 이 상태가 지속되는게 많아진다면 소켓이 고갈될 수 있다. 또한 잦은 TCP 3way handshake 비용이 발생한다.
- 이 문제를 막기 위해서 Client 측은 Connection pool 을 Server 측은 Keep-alive 설정을 해서 소켓을 재사용할 수 있다.
- close_wait 상태는 클라이언트가 접속을 끊기 위해 fin 요청을 보내서 ack 를 보내는 경우에 발생하는 상태인데 부하가 너무 많아서 ack 를 보내지 못하고 있는 경우에 close_wait 상태를 볼 수 있다.
- close_wait 상태를 지우려면 프로세스 종료나 네트워크 재시작을 해야한다. 즉 이것도 부하 테스트에서 해봐야한다.

## 애플리케이션 상태 진단하기

- Host 와 Network 가 문제가 없는데 느려지는 경우에는 애플리케이션을 봐야한다.
- 스레드를 살펴보는 경우는 크게 두 가지다.
    - 사용자 수가 많지도 않은데 CPU 사용률이 떨어지지 않을 때
    - 특정 요청을 했는데 (CPU 사용률은 문제가 없는데) 응답이 없을 때
    - 특정 스레드가 점유하고 있는 경우나 Lock 으로 인한 경우에 발생할 수 있다.
- 이는 Thread dump 를 통해서 분석이 가능하다.
    - Runnable 상태이면서 지속시간이 긴 스레드가 있는지.
    - Lock 이 제대로 처리되지 않아서 문제가 발생하고 있지 않은지

## 성능 개선하기

- web server, was 등을 개선하는 작업을 알아보자.
- DB 작업의 개선은 다음 주에.
- 성능 개선을 할 때 위에서 있는 지표들을 잘 사용하자.
    - Nginx 의 Reverse Proxy 에서 캐싱 설정과 keep-alive 설정, gzip 압축, 이미지 압축이 가능하다.
    - 이런 지표들을 테스트 해보자.
- 그리고 HTTP 프로토콜 개선을 통해서도 개선할 수 있다.
    - HTTP 1.0 은 연결마다 Connection 을 맺어서 TCP 연결 비용이 컸다. 이 연결 비용은 TCP 의 slow start 와 같은 것들이 있다.
    - HTTP 1.1 은 keep-alive 를 지원해서 계속해서 연결을 맺도록 해준다. timeout 시간이 지나면 확인 패킷을 보내고 응답을 받으면 다시 카운트. 응답을 받지 못하면 인터벌 타임 이후에 다시 요청을 보내고 여기서도 응답이 없으면 소켓을 닫는다. 하지만 여전히 문제가 있다. 요청과 응답 순서가 같아야 해서 동기적으로 주고받을 수 밖에 없다는 한계가 있다. 즉 한번에 보내고 하나씩 서버쪽에서 보내주는게 더 성능이 낫지않나? 해서 Pipelining 이 나왔다. 하지만 이 파이프라이닝도 서버에서 첫번째 요청이 길면 두 번째 요청이 느려지는 문제가 생기는 Head of line blocking 문제가 등장했다. 또 Multiple Connection 을 통해서 병렬성을 통해 성능 개선이 있었는데 대역폭을 많이 차지해서 latency 가 증가하는 문제가 있기도 했다.
    - HTTP/2 에서 multiplexing 을 통해서 요청 응답 순서에 상관없이 전달받더라도 서버 응답이 비동기 방식으로 처리된다. 즉 하나의 TCP 연결을 통해서도 여러 클라이언트의 요청을 보내는게 가능해졌다. 요청을 보낼 땐 Stream 방식으로 보낸다. 서버에서 이를 재조립해서 사용하고.


## Reverse Proxy 개선

- web-server 의 역할은 소켓을 생성해서 연결을 맺고 HTTP 요청을 이해하고 리소스에 접근한 후 응답을 생성해서 반환하는 역할을 한다. 동적인 요청의 경우에는 Servlet Conatiner 에게 위임을 하도록 하고.
- tomcat 의 경우에는 web-server + servlet conatiner 를 합쳤다.
- 서블릿 컨테이너는 스레드 풀의 개수만큼만 최대 요청을 허용한다. (기존)
- Reverse Proxy 에서는 클라이언트와의 커넥션을 어떻게 효율적으로 관리할지에 집중하고
- Tomcat 에서는 비즈니스 로직 개선, 조회 성능 개선에만 집중한다.
- Reverse Proxy 에서는 다음과 같은 것을 통해서 개선할 수 있다.
    - Contents-encoding: gzip
- tomcat 에서는 다음과 같은 것을 통해서 개선할 수 있다.
    - Etag: 정적리소스를 매번 재전송하는게 아니라 Etag 를 통해서 서버에서 변경여부만 파악하는 것.
    - Cache-Control 를 통해서 리소스 접근을 캐시할 수 있다. 캐시가 가능하지 않다면 No-Store 를 설정하면 된다

## ETC

- 성능 개선과 클린 코드는 목표치를 보고 하는게 아니다.
- 어느정도까지 사용자들이 허용가능한지 목표를 알고 있어야 한다.