## Kafka

https://www.linkedin.com/pulse/avoiding-message-losses-duplication-lost-multiple-kafka-mahesh-abnave/

#### Consumer 가 데이터 중복을 처리하지 않게 하기 위해선 어떻게 해야하는가? 

Consumer 가 데이터를 처리했다!. 라는 걸 할 수 있는 옵션으로 비동기 식으로 진행하는 Auto Commit 과 
수동적으로 Commit 하는 방법이 있다. 

자동 커밋하는 방법은 커밋하기 전에 리밸런싱이 일어난다면 데이터를 중복으로 처리해야할거니까 
데이터를 처리한 시점에 처리했다고 커밋을 날려주는 수동 커밋을 이용해야한다. 
수동 커밋을 할 때 신경써야하는 점은 데이터를 가져오고 커밋을 하는게 아니라 데이터를 온전히 데이터베이스에 반영했다는 그 시점에 수동 커밋을 해주는게 중요하다.

하지만 이 경우에도 데이터베이스에 반영을 했는데 커밋을 하지 못하고 셧다운이 된다면 데이터를 중복으로 처리하는 경우가 생긴다. 

Graceful Shutdown 이라고해서 커밋을 반드시 하는 방법이 있는데 이러면 또 데이터를 처리하지 않았을때도 커밋을 하게되서 손실이 발생하게 되는 경우도 있을 것 같다. 
데이터를 처리하지 않았더라면 commit 을 하지 않고. 데이터를 처리했더라면 commit 을 하는 방법이 있다.

그리고 Kafka commit() 자체가 실패할 가능성도 고려해야한다. 그런 경우에 이제 이전에 처리한 메시지들을
다시 만나는 경우가 있는데 이런 경우를 고려해서 인메모리 데이터 스트럭쳐인 REDIS 에 하나의 키 값으로 메시지를 
몇번까지 처리했는지를 값을 넣도록 했다. 물론 보내는 메시지 자체에 Sequence Number 가 있도록 했고.  


#### Producer 가 보낸 메시지가 유실되지 않도록 하기 위해선 어떻게 해야할까? 

Kafka Producer 가 성공적으로 메시지를 보냈다! 를 설정하는 옵션으로 
브로커에 있는 파티션 리더만 받고 성공했다 가 있고, 리더와 팔로우 모두 받았다가 있고, 아무도 안받았다가 있다.

이 경우에 메시지 손실을 극도로 없애기 위해서 카프카의 리더와 팔로우 모두 받도록 설정을 한다. 하지만 이 경우
프로듀서에게 오는 Latency 가 길어지기 떄문에 브로커에서 설정하는 옵션으로 팔로우가 최소한 이정도만 받아도
프로듀서에게 성공적으로 보내겠다라는 옵션이 있는 `min.insync.replicas` 옵션을 설정해놓으면 응답시간도
빠르게 유지하는게 가능하다.    

그리고 `min.insync.replicas` 같은 경우 파티션의 모든 개수와 동일하게 된다면 파티션 하나만 장애가 나더라도 ACK 를 날릴 수 없기 때문에
이를 주의하려고 노력했다. 

#### Producer 가 보낸 메시지를 중복으로 보내지 않게 하려면 어떻게 해야할까? 

메시지를 보낼 떄 브로커 이슈나 네트워크 이슈로 인해서 패킷을 받았다는 Ack 신호가 늦게 오는 경우가 있다. 
이 경우 retry 를 하는데 이러면 메시지가 중복으로 보내져서 순서가 맞지 않게 되는 경우가 있다.  

이를 해결하는 옵션으로 `enable.idempotence=true` 로 설정하면 프로듀서가 브로커에게 보내는 메시지에
프로듀서 ID 와 메시지 Sequence 번호가 담기게 되고 브로커는 이것들을 보고 Sequence 번호가 낮은 메시지를 버린다.  

또 파티션의 리더의 리밸런싱으로 인해서 메시지가 유실되는 경우가 생길 수 있으므로 `acks=all` 로 설정을 해야한다.  

#### Producer 가 보낸 메시지를 순서대로 유지시키기 위해선 어떻게 해야할까? 

특정 메시지의 순서는 파티션별로 순서가 이뤄지니까 여러 파티션에 메시지를 골고루 보내도 되는지, 하나의 파티션에서만 보내야하는지 이를 일단 고민해봐야한다. 

카프카 Producer 에서 한 커넥션에서 최대 전송할 수 있는 요청의 개수가 있는 옵션이 있다. 

`max.in.flight.requests.per.connection` 이 있는데 이 값이 1 보다 크다면 한번에 프로듀서가
배치 메시지를 여러개 보내는데 그 경우 한 메시지는 실패하고 한 메시지는 성공한다면 실패한 메시지는 retry 하게되고
이를 통해서 메시지 순서가 뒤바뀌는 경우가 존재한다. 그러므로 이 `max.in.flight.requests.per.connection` 값을 1로 설정하면 된다. 

#### 카프카에서 발생할 수 있는 에러 유형

- 전송 과정에서 실패

  - 브로커에서 설정한 메시지보다 프로듀서가 보낸 메시지가 더 큰 경우
  
  - 일시적인 네트워크 오류로 인해 타임아웃이 난 경우
  
  - 리더가 다운되고 새 리더가 선출되고 있는 경우 
  
- 전송 전에 실패

  - 프로듀서 버퍼가 차는 속도가 네트워크 스레드로 브로커에게 보내는 속도보다 빠른 경우에 버퍼가 다차서 
  유실되는 경우 
  
  - 직렬화 실패나 프로듀서가 보낼 수 있는 자체 크기를 넘은 경우 
  
#### 카프카에서 실패를 한 경우에 대응은 어떻게?

- 기본적으로 Exception 에 따라서 retry 를 해야하는거면 retry 를 하고 별도의 오브젝트 스토로지에다가 
에러사항을 기록해두는 것.      